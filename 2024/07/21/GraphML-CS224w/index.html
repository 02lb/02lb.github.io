<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="图表示学习&#x2F;图机器学习CS224W: Machine Learning with Graphs GuideLines Methods for node embeddings: DeepWalk, Node2Vec  Graph Neural Networks: GCN, GraphSAGE, GAT…  Graph Transformers  Knowledge graphs and r">
<meta property="og:type" content="article">
<meta property="og:title" content="GraphML-CS224w【图机器学习】">
<meta property="og:url" content="https://02lb.github.io/2024/07/21/GraphML-CS224w/index.html">
<meta property="og:site_name" content="Bo Li’s Blog">
<meta property="og:description" content="图表示学习&#x2F;图机器学习CS224W: Machine Learning with Graphs GuideLines Methods for node embeddings: DeepWalk, Node2Vec  Graph Neural Networks: GCN, GraphSAGE, GAT…  Graph Transformers  Knowledge graphs and r">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723085223291.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723084716757.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723084751025.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723084807550.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-21%2017.02.31.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-21%2017.07.23.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723085237389.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2015.41.27.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.11.46.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.18.05.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.20.58.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.31.53.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.38.30.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.42.25.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.43.26.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.44.18.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2017.05.24.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723085117822.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-23%2009.22.39.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723104152426.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723104136425.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723105202851.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-23%2011.54.37.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723120112059.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-23%2012.00.31.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723123526056.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.08.33.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-26%2010.50.16.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2010.02.59.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2010.05.34.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2010.18.21.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2010.20.11.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240729111639298.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.16.31.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.18.03.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.18.22.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240729111944075.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.22.37.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240729122411091.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.05.59.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.10.50.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.18.02.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.22.48.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.28.52.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.28.08.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.30.35.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.40.29.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.43.28.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.52.13.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.53.39.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.58.25.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.58.45.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.58.53.png">
<meta property="article:published_time" content="2024-07-21T09:26:48.000Z">
<meta property="article:modified_time" content="2024-07-29T06:00:45.981Z">
<meta property="article:author" content="Lee">
<meta property="article:tag" content="图机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723085223291.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.png">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>GraphML-CS224w【图机器学习】</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 7.1.1"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/02lb">Projects</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2024/07/22/RecSys/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2024/04/12/docker/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://02lb.github.io/2024/07/21/GraphML-CS224w/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&text=GraphML-CS224w【图机器学习】"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&is_video=false&description=GraphML-CS224w【图机器学习】"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=GraphML-CS224w【图机器学习】&body=Check out this article: https://02lb.github.io/2024/07/21/GraphML-CS224w/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&name=GraphML-CS224w【图机器学习】&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://02lb.github.io/2024/07/21/GraphML-CS224w/&t=GraphML-CS224w【图机器学习】"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0-%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">图表示学习&#x2F;图机器学习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#GuideLines"><span class="toc-number">1.0.0.1.</span> <span class="toc-text">GuideLines</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day1"><span class="toc-number">1.1.</span> <span class="toc-text">Day1:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Node-Embedding"><span class="toc-number">1.1.1.</span> <span class="toc-text">Node Embedding</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Encoder-Decoder-Framework"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">Encoder - Decoder Framework</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0%EF%BC%9ARandom-Walk%EF%BC%9A"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">随机游走：Random Walk：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%9D%E6%83%B3%EF%BC%88Idea%EF%BC%89"><span class="toc-number">1.1.1.2.1.</span> <span class="toc-text">思想（Idea）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%EF%BC%88Expressivity%EF%BC%89"><span class="toc-number">1.1.1.2.2.</span> <span class="toc-text">表达能力（Expressivity）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%9F%E9%87%87%E6%A0%B7-Negative-Sampling%EF%BC%9A"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">负采样 Negative Sampling：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B4%9F%E9%87%87%E6%A0%B7%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">1.1.1.3.1.</span> <span class="toc-text">负采样的原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B4%9F%E6%A0%B7%E6%9C%AC%E6%95%B0%E9%87%8F-K-%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.1.1.3.2.</span> <span class="toc-text">负样本数量 (K) 的选择</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.1.1.3.3.</span> <span class="toc-text">负样本的选择</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A%E8%B4%9F%E9%87%87%E6%A0%B7%E5%85%AC%E5%BC%8F%E5%8F%8A%E5%85%B6%E5%8E%9F%E7%90%86"><span class="toc-number">1.1.1.3.4.</span> <span class="toc-text">解释负采样公式及其原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Node-Embedding-%EF%BC%9A-DeepWalk-Node2Vec"><span class="toc-number">1.1.2.</span> <span class="toc-text">Node Embedding ： DeepWalk &#x2F; Node2Vec</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Graph-Embedding-%EF%BC%9A%E5%9B%BE%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">Graph Embedding ：图嵌入</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day1-Lab"><span class="toc-number">1.2.</span> <span class="toc-text">Day1-Lab:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day2"><span class="toc-number">1.3.</span> <span class="toc-text">Day2:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CORE%EF%BC%9AGraph-Neural-Network"><span class="toc-number">1.3.1.</span> <span class="toc-text">CORE：Graph Neural Network</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Graph-vs-Image"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">Graph vs Image</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GNN-Basics"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">GNN Basics</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Classic-GNN"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">Classic GNN</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day3"><span class="toc-number">1.4.</span> <span class="toc-text">Day3</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9%EF%BC%9AGNN"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">主要内容：GNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Graph-Manipulation%E3%80%90%E5%9B%BE%E5%A4%84%E7%90%86%E3%80%91"><span class="toc-number">1.4.0.2.</span> <span class="toc-text">Graph Manipulation【图处理】</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#unsupervised-self-supervised"><span class="toc-number">1.4.0.3.</span> <span class="toc-text">unsupervised &#x2F; self- supervised</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">1.4.0.4.</span> <span class="toc-text">评估指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%BE%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%92%E5%88%86"><span class="toc-number">1.4.0.5.</span> <span class="toc-text">图数据的划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#The-Power-of-GNN"><span class="toc-number">1.4.0.6.</span> <span class="toc-text">The Power of GNN</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day3-Lab"><span class="toc-number">1.5.</span> <span class="toc-text">Day3-Lab</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84GCN%E7%94%A8%E4%BA%8E%E8%8A%82%E7%82%B9%E9%A2%84%E6%B5%8B"><span class="toc-number">1.5.0.1.</span> <span class="toc-text">实现一个简单的GCN用于节点预测</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day4"><span class="toc-number">1.6.</span> <span class="toc-text">Day4</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Heterogenous-graphs-%E5%BC%82%E8%B4%A8%E5%9B%BE"><span class="toc-number">1.6.0.1.</span> <span class="toc-text">Heterogenous graphs[异质图]</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E7%B3%BB%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%EF%BC%88Relational-Graph-Convolutional-Network-R-GCN%EF%BC%89"><span class="toc-number">1.6.0.2.</span> <span class="toc-text">关系图卷积网络（Relational Graph Convolutional Network, R-GCN）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GNN-vs-Heterogenous-GNN"><span class="toc-number">1.6.0.3.</span> <span class="toc-text">GNN vs Heterogenous GNN</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day5"><span class="toc-number">1.7.</span> <span class="toc-text">Day5</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Knowledge-Graphs"><span class="toc-number">1.7.0.1.</span> <span class="toc-text">Knowledge Graphs</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.7.0.2.</span> <span class="toc-text">关系模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KG-Completion"><span class="toc-number">1.7.0.3.</span> <span class="toc-text">KG Completion</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KG-Reasoning"><span class="toc-number">1.7.0.4.</span> <span class="toc-text">KG Reasoning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Query2Box"><span class="toc-number">1.7.0.5.</span> <span class="toc-text">Query2Box</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day6"><span class="toc-number">1.8.</span> <span class="toc-text">Day6</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day7"><span class="toc-number">1.9.</span> <span class="toc-text">Day7</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day8"><span class="toc-number">1.10.</span> <span class="toc-text">Day8</span></a></li></ol></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        GraphML-CS224w【图机器学习】
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">Lee</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2024-07-21T09:26:48.000Z" class="dt-published" itemprop="datePublished">2024-07-21</time>
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag">图机器学习</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <h1 id="图表示学习-图机器学习"><a href="#图表示学习-图机器学习" class="headerlink" title="图表示学习&#x2F;图机器学习"></a>图表示学习&#x2F;图机器学习</h1><p><a target="_blank" rel="noopener" href="https://web.stanford.edu/class/cs224w/">CS224W: Machine Learning with Graphs</a></p>
<h4 id="GuideLines"><a href="#GuideLines" class="headerlink" title="GuideLines"></a>GuideLines</h4><ul>
<li>Methods for node embeddings: DeepWalk, Node2Vec </li>
<li>Graph Neural Networks: GCN, GraphSAGE, GAT… </li>
<li>Graph Transformers </li>
<li>Knowledge graphs and reasoning: TransE, BetaE </li>
<li>Generative models for graphs: GraphRNN </li>
<li>Graphs in 3D: Molecules § Scaling up to large graphs </li>
<li>Applications to Biomedicine, Science, Technology</li>
</ul>
<h2 id="Day1"><a href="#Day1" class="headerlink" title="Day1:"></a>Day1:</h2><h3 id="Node-Embedding"><a href="#Node-Embedding" class="headerlink" title="Node Embedding"></a>Node Embedding</h3><p><img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723085223291.png" alt="image-20240723085223291"></p>
<blockquote>
<p>Core idea: <strong>Embed nodes so that distances in embedding space reflect node similarities in the original network.</strong></p>
</blockquote>
<p>对节点进行自动的特征提取-自动嵌入&#x2F;编码：被下游任务利用</p>
<h4 id="Encoder-Decoder-Framework"><a href="#Encoder-Decoder-Framework" class="headerlink" title="Encoder - Decoder Framework"></a><strong>Encoder - Decoder Framework</strong></h4><ul>
<li>encoder 就是node embedding</li>
<li>decoder 就是对节点vector 做相似度提取：例如内积相似度</li>
</ul>
<h4 id="随机游走：Random-Walk："><a href="#随机游走：Random-Walk：" class="headerlink" title="随机游走：Random Walk："></a><strong>随机游走：Random Walk：</strong></h4><ul>
<li><h5 id="思想（Idea）"><a href="#思想（Idea）" class="headerlink" title="思想（Idea）"></a>思想（Idea）</h5><p>  核心思想是：如果从节点 u 开始的随机游走高概率访问节点 v，那么 u 和 v 是相似的。具体解释如下：</p>
<ol>
<li><strong>访问概率高</strong>：从节点 u 开始的随机游走如果高概率访问节点 v，这意味着 u 和 v 之间的路径很多，或者有很多共同的邻居。这说明 u 和 v 在图中的结构位置很相似，具有相似的网络结构特征。</li>
<li><strong>多跳信息</strong>：随机游走不仅考虑直接的邻居关系，还会通过多跳路径访问更远的节点。这种方式可以捕捉到网络中更复杂的结构信息和节点之间的关系。例如，两个节点即使不直接相连，但如果它们通过多个中间节点有较高的访问概率，那么它们之间仍然具有潜在的相似性。</li>
</ol>
</li>
<li><h5 id="表达能力（Expressivity）"><a href="#表达能力（Expressivity）" class="headerlink" title="表达能力（Expressivity）"></a>表达能力（Expressivity）</h5><p>  随机游走路径通过灵活的随机定义方式捕捉节点之间的相似度，能够同时包含局部和高阶的邻域信息：</p>
<ol>
<li><strong>局部信息</strong>：随机游走会优先访问与起始节点直接相连的节点，这样能够捕捉节点的局部结构信息。如果两个节点在局部结构上相似（例如，它们有很多共同邻居），那么随机游走路径会较高概率访问到这些共同邻居。</li>
<li><strong>高阶信息</strong>：随着随机游走的步数增加，它会逐渐扩展到更多的邻居节点，甚至是更远的节点。这样可以<strong>捕捉到多跳（multi-hop）的关系信息，即高阶邻域信息。</strong>如果两个节点在网络中的更大范围内具有相似的连接模式，随机游走路径也能反映这一点。</li>
</ol>
</li>
<li><p>随机游走最大化目标节点embedding的对数似然（使得目标节点周围节点的似然概率最大化，原理是周围节点在嵌入向量空间时距离也相对近），这个计算过程可以使用负采样进行优化。</p>
</li>
</ul>
<h4 id="负采样-Negative-Sampling："><a href="#负采样-Negative-Sampling：" class="headerlink" title="负采样 Negative Sampling："></a>负采样 Negative Sampling：</h4><ul>
<li><h5 id="负采样的原理"><a href="#负采样的原理" class="headerlink" title="负采样的原理"></a>负采样的原理</h5><p>  <strong>负采样的核心思想是用一部分负样本来近似整个负样本空间，从而减少计算开销。</strong>具体步骤如下：</p>
<ol>
<li><strong>选择正样本</strong>：即实际存在的节点对（例如，图中的实际边）。</li>
<li><strong>选择负样本</strong>：随机选择一些节点对（图中不存在的边），这些对作为负样本。</li>
</ol>
</li>
<li><h5 id="负样本数量-K-的选择"><a href="#负样本数量-K-的选择" class="headerlink" title="负样本数量 (K) 的选择"></a>负样本数量 (K) 的选择</h5><ul>
<li><strong>更高的 (K) 值</strong>：提供更鲁棒的估计，因为更多的负样本能够更好地近似整个负样本空间。但是这也会增加计算开销。</li>
<li><strong>更低的 (K) 值</strong>：减少计算开销，但可能会增加对负事件的偏差。</li>
</ul>
<p>  在实际应用中， (K) 通常选择在5到20之间，以平衡计算效率和估计精度。</p>
</li>
<li><h5 id="负样本的选择"><a href="#负样本的选择" class="headerlink" title="负样本的选择"></a>负样本的选择</h5><p>  负样本可以是任何节点，不一定要与随机游走无关。为了提高效率，常常会从所有节点中随机选择负样本，而不是仅从未在随机游走中出现的节点中选择。</p>
</li>
<li><h5 id="解释负采样公式及其原理"><a href="#解释负采样公式及其原理" class="headerlink" title="解释负采样公式及其原理"></a>解释负采样公式及其原理</h5><p>  负采样是一种用于<strong>提高训练效率和计算效率的方法</strong>，尤其是在处理大规模数据集时。下面我们详细解释给定的公式和相关概念。</p>
<p>  给定的公式：<br>  $$<br>  \log \left( \frac{\exp(\mathbf{z}_v^\top \mathbf{z}<em>u)}{\sum</em>{n \in N} \exp(\mathbf{z}_n^\top \mathbf{z}_u)} \right) \approx \log \sigma(\mathbf{z}_v^\top \mathbf{z}<em>u) + \sum</em>{k&#x3D;1}^K \log \sigma(-\mathbf{z}_n^\top \mathbf{z}_u)<br>  $$</p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723084716757.png" alt="image-20240723084716757" style="zoom: 50%;" />
  
<p>  其中：</p>
<ul>
<li>$\mathbf{z}_v$ 和 $\mathbf{z}_u$是节点$v$ 和 $u$ 的嵌入向量。</li>
<li>$\sigma(x)$是sigmoid函数，定义为 $\sigma(x) &#x3D; \frac{1}{1 + \exp(-x)}$。</li>
<li>$N$ 是所有节点的集合。</li>
<li>$K$ 是负样本的数量。</li>
<li>$\mathbf{z}_n$ 是负样本节点的嵌入向量。</li>
</ul>
<p>  公式表示：</p>
<ul>
<li><p>左边的<br>  $$<br>  \log \left( \frac{\exp(\mathbf{z}_v^\top \mathbf{z}<em>u)}{\sum</em>{n \in N} \exp(\mathbf{z}_n^\top \mathbf{z}_u)} \right)<br>  $$</p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723084751025.png" alt="image-20240723084751025" style="zoom:50%;" />

<p>  是softmax的对数。</p>
</li>
<li><p>右边的<br>  $$<br>  \log \sigma(\mathbf{z}_v^\top \mathbf{z}<em>u) + \sum</em>{k&#x3D;1}^K \log \sigma(-\mathbf{z}_n^\top \mathbf{z}_u)<br>  $$</p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723084807550.png" alt="image-20240723084807550" style="zoom:50%;" />
  
<p>  是<strong>负采样的对数近似。</strong></p>
</li>
</ul>
<p>  <strong>&#x3D;&#x3D;通过负采样，我们可以将计算从整个节点集合的softmax归约到少量负样本的log-sigmoid函数计算，从而大大减少计算复杂度。&#x3D;&#x3D;</strong></p>
</li>
</ul>
<h3 id="Node-Embedding-：-DeepWalk-Node2Vec"><a href="#Node-Embedding-：-DeepWalk-Node2Vec" class="headerlink" title="Node Embedding ： DeepWalk &#x2F; Node2Vec"></a>Node Embedding ： DeepWalk &#x2F; Node2Vec</h3><blockquote>
<p><strong>重点内容</strong></p>
</blockquote>
<ul>
<li><p>DeepWalk：RandomWalk + 词嵌入模型（如Word2Vec）</p>
</li>
<li><p>Node2Vec：DeepWalk + 利用了参数p、q进行BFS&#x2F;DFS的随机游走，提供了biased的路径选择。</p>
<blockquote>
<p>引入了更灵活的随机游走策略，通过调整参数 p 和 q 来控制游走的行为，从而在深度优先搜索（DFS）和广度优先搜索（BFS）之间进行平衡。</p>
</blockquote>
</li>
<li><p>利用随机游走得到的node-seq视为word2vec的词序列进行embedding</p>
</li>
<li><p><strong>Limitations：</strong></p>
<ul>
<li><p><strong>模型不能推广到训练和测试集中未见过的新节点或新结构：</strong>若new node到来，需要重新计算整个graph的node embedding，而不是增量可扩展的。</p>
</li>
<li><p><strong>无法捕捉结构相似性</strong>：它们只是用过节点的相邻性来判断空间相似性（距离），而不考虑任何结构信息</p>
<blockquote>
<p>主要捕捉的是<strong>节点的同质性（homophily）特征</strong>，而不是<strong>结构相似性（structural similarity）</strong>。这意味着它们倾向于将相邻或近邻节点（即在图中距离较近的节点）映射到相似的嵌入空间中，而不是将具有相似结构但在图中距离较远的节点映射到相似的嵌入空间中。</p>
<p>节点同质性假设是指在图中距离较近的节点往往具有相似的特征或属性。例如，在社交网络中，朋友之间的兴趣爱好往往相似。</p>
<p>结构相似性是指两个节点在图中的角色或位置相似，即使它们在图中距离较远。例如，在公司组织图中，两个不同部门的经理可能具有类似的结构角色，即使他们不直接连接。</p>
</blockquote>
</li>
<li><p>Solution to these limitations: <strong>Deep Representation Learning and Graph Neural Networks</strong></p>
</li>
</ul>
</li>
</ul>
<h4 id="Graph-Embedding-：图嵌入"><a href="#Graph-Embedding-：图嵌入" class="headerlink" title="Graph Embedding ：图嵌入"></a>Graph Embedding ：图嵌入</h4><ul>
<li><p>Naive：将所有node的嵌入向量进行结合操作（累加&#x2F;avg&#x2F;……)</p>
</li>
<li><p>Approach2: 添加一个 上帝虚节点 </p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-21%2017.02.31.png" style="zoom: 25%;" />
</li>
<li><p>Aprroach3 ：分层&#x2F;pool：<strong>DiffPool（Differentiable Pooling）</strong></p>
<blockquote>
<p>是一种图神经网络（GNN）池化方法，用于在图上进行层次化聚类，并根据这些聚类对节点嵌入进行求和或平均。</p>
</blockquote>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-21%2017.07.23.png" style="zoom: 33%;" />



<h2 id="Day1-Lab"><a href="#Day1-Lab" class="headerlink" title="Day1-Lab:"></a>Day1-Lab:</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1vvIoEqxGl1naopTZbh4bmCOLEiCxvcQq">Link</a></p>
</blockquote>
<p>熟悉 NetworkX 以及 PyG 的用法；简单的 NodeEmbedding方法</p>
<h2 id="Day2"><a href="#Day2" class="headerlink" title="Day2:"></a>Day2:</h2><h3 id="CORE：Graph-Neural-Network"><a href="#CORE：Graph-Neural-Network" class="headerlink" title="CORE：Graph Neural Network"></a>CORE：Graph Neural Network</h3><p><img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723085237389.png" alt="image-20240723085237389"></p>
<blockquote>
<p>之前的Node Embedding方法（简单的 encoder - decoder）没有考虑节点结构的信息，只是使用节点距离进行空间嵌入；这里使用GNN深度学习的方法学习节点的嵌入；</p>
</blockquote>
<h4 id="Graph-vs-Image"><a href="#Graph-vs-Image" class="headerlink" title="Graph vs Image"></a>Graph vs Image</h4><ul>
<li><p>There is no fixed notion of locality or sliding window on the graph (图上<strong>没有固定的局部性或滑动窗口概念</strong>)</p>
</li>
<li><p>辨析：<strong>排列不变性（permutation invariant）</strong>，不存在一种对节点的权威的排序，任何排序应该有相同的结果；<strong>排列等变性（permutation equivariant）</strong>；</p>
<blockquote>
<p>排列不变性意味着，无论图的节点顺序如何，模型的输出结果应该保持不变。假设我们有一个图 $G$，其邻接矩阵为 $A$，节点特征矩阵为 $X$，则排列不变性可以表示为：</p>
<p>$ f(A, X) &#x3D; f(PAP^T, PX) $</p>
<p>其中，$P$ 是一个任意的排列矩阵，它可以重新排列图的节点。排列不变性的一个例子是将图映射到一个固定长度的向量。无论如何重新排列输入图的节点，输出向量始终保持不变。</p>
</blockquote>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2015.41.27.png" alt="截屏2024-07-22 15.41.27" style="zoom: 25%;" />



<h4 id="GNN-Basics"><a href="#GNN-Basics" class="headerlink" title="GNN Basics"></a>GNN Basics</h4><ul>
<li><p>Param sharing：参数共享</p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.11.46.png" alt="截屏2024-07-22 16.11.46" style="zoom: 25%;" />


</li>
<li><p>GNN beyond CNN&#x2F;Transformers</p>
<ul>
<li><strong>CNNs can be seen as a special GNN with fixed neighbor</strong></li>
</ul>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.18.05.png" alt="截屏2024-07-22 16.18.05" style="zoom:25%;" />

<ul>
<li><strong>Transformer layer can be seen as a special GNN that runs on a fullyconnected “word” graph!</strong></li>
</ul>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.20.58.png" alt="截屏2024-07-22 16.20.58" style="zoom:25%;" /></li>
</ul>
<h4 id="Classic-GNN"><a href="#Classic-GNN" class="headerlink" title="Classic GNN"></a>Classic GNN</h4><ul>
<li><p>一个通用的GNN架构：</p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.31.53.png" alt="截屏2024-07-22 16.31.53" style="zoom:25%;" />
</li>
<li><p><strong>GNN Layer &#x3D;（1） Message + （2）Aggregation</strong></p>
<blockquote>
<p>不同的策略 -&gt; 不同的实例：GCN, GraphSAGE, GAT…..</p>
</blockquote>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.38.30.png" alt="截屏2024-07-22 16.38.30" style="zoom: 25%;" />
</li>
<li><p><strong>Graph Convolutional Networks (GCN)：</strong></p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.42.25.png" alt="截屏2024-07-22 16.42.25" style="zoom:25%;" />
</li>
<li><p><strong>GraphSAGE：</strong></p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.43.26.png" alt="截屏2024-07-22 16.43.26" style="zoom:25%;" />

<ul>
<li><p><strong>Graph Attention Networks（GAT）：</strong></p>
<blockquote>
<p>Idea: <strong>Not all node’s neighbors are equally important</strong>；the NN should devote more computing power on that small but important part of the data. 【NN应该在数据中那个小而重要的部分上投入更多的计算能力。】</p>
</blockquote>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2016.44.18.png" alt="截屏2024-07-22 16.44.18" style="zoom:25%;" />

<ul>
<li>Key benefit: Allows for (implicitly) specifying different importance values ($\alpha_{vu}$) to different neighbors</li>
</ul>
</li>
<li><p><strong>over-smoothing problem【过度平滑</strong>】：当stack的GNN层过多时，节点的感知域【Receptive field】可能过大甚至覆盖整个Graph，导致所有节点都感知整个图，使得所有节点趋于相同的embedding；</p>
<blockquote>
<p>Key：the embedding of a node is <strong>determined by its receptive field</strong></p>
</blockquote>
<ul>
<li>过多堆叠GNN Layer往往没用（不像CNN Layer那么有效），所以需要在GNN Layer较少（Shallow）的时候试图增强其感知能力</li>
<li>通过增强其message&#x2F;Aggregation模块的NN的学习能力&#x2F;通过前后concat线性层&#x2F;通过添加 <strong>skip connection</strong>（集成学习视角）</li>
</ul>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-22%2017.05.24.png" alt="截屏2024-07-22 17.05.24" style="zoom:25%;" />
</li>
<li><p>图增强&#x2F;处理：应对稀疏图&#x2F;稠密图&#x2F;图过大等问题进行特征增强&#x2F;图处理</p>
<ul>
<li>Graph Manipulation: Feature augmentation &#x2F; Structure manipulation</li>
<li>后面的内容会cover这部分</li>
</ul>
</li>
</ul>
<h2 id="Day3"><a href="#Day3" class="headerlink" title="Day3"></a>Day3</h2><h4 id="主要内容：GNN"><a href="#主要内容：GNN" class="headerlink" title="主要内容：GNN"></a>主要内容：GNN</h4><p><img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723085117822.png" alt="image-20240723085117822"></p>
<h4 id="Graph-Manipulation【图处理】"><a href="#Graph-Manipulation【图处理】" class="headerlink" title="Graph Manipulation【图处理】"></a>Graph Manipulation【图处理】</h4><ul>
<li><p>Graph Feature manipulation </p>
<ul>
<li>The input graph lacks features —— <strong>feature augmentation</strong></li>
</ul>
</li>
<li><p>Graph Structure manipulation </p>
<ul>
<li><p><strong>The graph is too sparse</strong> —— Add virtual nodes &#x2F; edges </p>
<blockquote>
<p>稀疏图：通常添加两跳虚边；例如在作者-文章的二部图中可以连接同一篇paper的coop的作者</p>
</blockquote>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-23%2009.22.39.png" alt="截屏2024-07-23 09.22.39" style="zoom:15%;" />
</li>
<li><p><strong>The graph is too dense</strong> —— Sample neighbors when doing message passing </p>
<blockquote>
<p>消息传递时随机采样而不使用所有的节点；和使用所有的子节点进行训练的期望一致，但是可以减少训练开销</p>
</blockquote>
</li>
<li><p><strong>The graph is too large</strong> —— Sample subgraphs to compute embeddings</p>
</li>
</ul>
</li>
</ul>
<h4 id="unsupervised-self-supervised"><a href="#unsupervised-self-supervised" class="headerlink" title="unsupervised &#x2F; self- supervised"></a>unsupervised &#x2F; self- supervised</h4><blockquote>
<p>我理解的这两个概念的区分：无监督更多的不设置标签例如clustering；自监督需要自己创建的标签；</p>
</blockquote>
<ol>
<li><strong>Node Level：</strong>使用节点的统计量作为标签进行训练， such as clustering coefficient, PageRank, …</li>
<li><strong>Edge Level：</strong>把一些edge进行遮蔽hide&#x2F;mask进行作为标签进行训练</li>
<li><strong>Graph Level：</strong>图同构信息</li>
</ol>
<h4 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h4><ul>
<li>二分类模型的评估：混淆矩阵 &#x2F; TPR&#x3D;&#x3D;RecallRate &#x2F; ROC（AUC）</li>
<li>ROC曲线的xy坐标为两个rate：FPR以及TPR，性能越好的分类模型TPR&gt;&gt;FPR；如何绘制？对一个模型取不同的<strong>阈值</strong>分别计算FPR以及TPR坐标图中的一个点，形成曲线</li>
</ul>
<h4 id="图数据的划分"><a href="#图数据的划分" class="headerlink" title="图数据的划分"></a>图数据的划分</h4><blockquote>
<p>和其它的NN不相同，图数据集不是分离的数据点，所以需要特殊的数据划分(train&#x2F;valid&#x2F;test)；这一部分的内容设计更加复杂的划分方法，在很多论文有所涉及，这里论述的只是最基础的划分方法。</p>
</blockquote>
<ul>
<li><p><strong>Transductive Setting</strong>【直推】</p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723104152426.png" alt="image-20240723104152426" style="zoom:33%;" />

<ol>
<li><p><strong>定义</strong>：在Transductive setting中，训练数据和测试数据的节点都属于同一个图。<strong>模型可以在训练时访问整个图的结构信息</strong>，包括测试节点及其连接，但不能访问测试节点的标签。</p>
</li>
<li><p><strong>特点</strong>：</p>
<ul>
<li><strong>同一个图</strong>：训练和测试都在同一个图上进行，测试节点在训练时是已知的。</li>
<li><strong>全局信息</strong>：模型可以利用整个图的结构信息来进行学习，这包括训练节点和测试节点之间的连接。</li>
<li><strong>目标</strong>：学习节点的嵌入或特征，使得在测试节点上的分类或回归任务表现良好。【Only applicable to node &#x2F; edge prediction tasks】无法在Graph-Level分类相关的任务使用。</li>
</ul>
</li>
</ol>
</li>
<li><p><strong>Inductive Setting</strong>【归纳】</p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723104136425.png" alt="image-20240723104136425" style="zoom: 33%;" />

<ol>
<li><p><strong>定义</strong>：在Inductive setting中，训练数据和测试数据的节点属于不同的图。<strong>模型在训练时只能访问训练图的结构和标签信息，测试时模型需要在完全未知的图或新节点上进行预测。</strong></p>
</li>
<li><p>特点：</p>
<ul>
<li><strong>不同的图</strong>：训练和测试在不同的图上进行，或者在同一个图上但测试节点在训练时是未知的。</li>
<li><strong>局部信息</strong>：模型不能利用测试图的结构信息进行训练，只能基于训练图进行学习。</li>
<li><strong>目标</strong>：在新的图或新节点上<strong>泛化良好</strong>，即使这些图或节点在训练时不可见。【Applicable to node &#x2F; edge &#x2F; graph tasks】</li>
</ul>
</li>
</ol>
</li>
<li><p>具体示例：<strong>Transductive</strong> link prediction split：分为四类边【训练用信息边、训练用监督边、验证用边、测试用边】</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723105202851.png" alt="image-20240723105202851" style="zoom: 25%;" />



<h4 id="The-Power-of-GNN"><a href="#The-Power-of-GNN" class="headerlink" title="The Power of GNN"></a>The Power of GNN</h4><ul>
<li>对每个节点的计算可以构建一个计算图【Computational Graph】，对应一颗以该节点为根的子树；在该结构的<strong>aggragation聚合层</strong>为<strong>单射</strong>时其表达能力最强【单射可以区分不同的结构】</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-23%2011.54.37.png" alt="截屏2024-07-23 11.54.37" style="zoom: 25%;" />

<ul>
<li><p>Key observation: **Expressive power of GNNs can be characterized by that of neighbor aggregation functions they use.**【GNNs 的表达能力可以用其使用的 neighbor aggregation functions 所表征】</p>
</li>
<li><p><strong>e.g. failure 案例研究：</strong></p>
<ul>
<li><strong>GCN：</strong>使用平均池化</li>
</ul>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723120112059.png" alt="image-20240723120112059" style="zoom:25%;" />

<ul>
<li><strong>GraphSAGE：</strong>使用最大池化</li>
</ul>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-23%2012.00.31.png" alt="截屏2024-07-23 12.00.31" style="zoom:25%;" />

<ul>
<li><p>如上案例所示，GCN and GraphSAGE’s aggregation functions <strong>fail to distinguish some basic multi-sets【可重复元素集合】</strong>; <strong>hence not injective.【因此非most powerful】</strong></p>
</li>
<li><p>THE <strong>most expressive GNN</strong> in the class of message-passing GNNs：<strong>Graph Isomorphism Network (GIN)</strong> </p>
<blockquote>
<p>GIN‘s neighbor aggregation function is injective.</p>
</blockquote>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240723123526056.png" alt="image-20240723123526056" style="zoom:25%;" /></li>
</ul>
<h2 id="Day3-Lab"><a href="#Day3-Lab" class="headerlink" title="Day3-Lab"></a>Day3-Lab</h2><blockquote>
<p><a target="_blank" rel="noopener" href="https://colab.research.google.com/drive/1zunZQaGzLr782y3tkq3492rvw9UyY30I">Link</a></p>
<p>在Colab 2中，将<strong>使用PyTorch Geometric (PyG) 构建自己的图神经网络</strong>，并将该模型<strong>应用于两个Open Graph Benchmark (OGB)数据集</strong>。这两个数据集将用于基准测试你的模型在两个不同图任务上的性能：1）<strong>节点属性预测</strong>，预测单个节点的属性；2）<strong>图属性预测</strong>，预测整个图或子图的属性。</p>
</blockquote>
<h4 id="实现一个简单的GCN用于节点预测"><a href="#实现一个简单的GCN用于节点预测" class="headerlink" title="实现一个简单的GCN用于节点预测"></a>实现一个简单的GCN用于节点预测</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">GCN</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim, hidden_dim, output_dim, num_layers, dropout, return_embeds=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(GCN, self).__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># GCNConv层列表</span></span><br><span class="line">        self.convs = torch.nn.ModuleList()</span><br><span class="line">        <span class="comment"># 1D批归一化层列表</span></span><br><span class="line">        self.bns = torch.nn.ModuleList()</span><br><span class="line">        <span class="comment"># log softmax层</span></span><br><span class="line">        self.softmax = torch.nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建第一个GCN层</span></span><br><span class="line">        self.convs.append(torch_geometric.nn.GCNConv(input_dim, hidden_dim))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建剩余的GCN层和批归一化层</span></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_layers - <span class="number">1</span>):</span><br><span class="line">            self.convs.append(torch_geometric.nn.GCNConv(hidden_dim, hidden_dim))</span><br><span class="line">            self.bns.append(torch.nn.BatchNorm1d(hidden_dim))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建输出层</span></span><br><span class="line">        self.convs.append(torch_geometric.nn.GCNConv(hidden_dim, output_dim))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 零化概率</span></span><br><span class="line">        self.dropout = dropout</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 是否返回节点嵌入</span></span><br><span class="line">        self.return_embeds = return_embeds</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">reset_parameters</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 重置所有GCN层的参数</span></span><br><span class="line">        <span class="keyword">for</span> conv <span class="keyword">in</span> self.convs:</span><br><span class="line">            conv.reset_parameters()</span><br><span class="line">        <span class="comment"># 重置所有批归一化层的参数</span></span><br><span class="line">        <span class="keyword">for</span> bn <span class="keyword">in</span> self.bns:</span><br><span class="line">            bn.reset_parameters()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, adj_t</span>):</span><br><span class="line">        out = x</span><br><span class="line">        <span class="comment"># 应用第一个GCN层和ReLU激活</span></span><br><span class="line">        out = self.convs[<span class="number">0</span>](out, adj_t)</span><br><span class="line">        out = torch.nn.functional.relu(out)</span><br><span class="line">        out = torch.nn.functional.dropout(out, p=self.dropout, training=self.training)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用剩余的GCN层、批归一化、ReLU和dropout</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="built_in">len</span>(self.convs) - <span class="number">1</span>):</span><br><span class="line">            out = self.convs[i](out, adj_t)</span><br><span class="line">            out = self.bns[i-<span class="number">1</span>](out)</span><br><span class="line">            out = torch.nn.functional.relu(out)</span><br><span class="line">            out = torch.nn.functional.dropout(out, p=self.dropout, training=self.training)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 应用最终的GCN层</span></span><br><span class="line">        out = self.convs[-<span class="number">1</span>](out, adj_t)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果return_embeds为False，则应用log softmax</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> self.return_embeds:</span><br><span class="line">            out = self.softmax(out)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>



<h2 id="Day4"><a href="#Day4" class="headerlink" title="Day4"></a>Day4</h2><p><img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.08.33.png" alt="截屏2024-07-29 11.08.33"></p>
<h4 id="Heterogenous-graphs-异质图"><a href="#Heterogenous-graphs-异质图" class="headerlink" title="Heterogenous graphs[异质图]"></a>Heterogenous graphs[异质图]</h4><ul>
<li>异质图（Heterogeneous Graph）是指<strong>由不同类型的节点和边构成的图结构</strong>(a graph with multiple relation types)。 在异质图中，节点和边可以具有多样化的属性和关系，代表了不同实体以及它们之间的复杂关联。</li>
<li><strong>定义：</strong></li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-26%2010.50.16.png" alt="截屏2024-07-26 10.50.16" style="zoom:25%;" />

<ul>
<li><p>现实问题的Graph大多是异质图</p>
</li>
<li><p>可以将异质图中的节点&#x2F;边的类型编码为节点&#x2F;边的特征（例如one-hot）使得其变为标准图</p>
</li>
<li><p>How To Solve？</p>
</li>
</ul>
<h4 id="关系图卷积网络（Relational-Graph-Convolutional-Network-R-GCN）"><a href="#关系图卷积网络（Relational-Graph-Convolutional-Network-R-GCN）" class="headerlink" title="关系图卷积网络（Relational Graph Convolutional Network, R-GCN）"></a><strong>关系图卷积网络（Relational Graph Convolutional Network, R-GCN）</strong></h4><blockquote>
<p>是一种扩展了传统图卷积网络（GCN）的模型，专门用于处理异质图中的多种关系。<strong>R-GCN通过在图卷积操作中引入关系类型来捕捉不同类型节点和边之间的复杂关系。</strong>这使得R-GCN在处理包含多种关系的复杂图数据时更加有效。</p>
</blockquote>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2010.02.59.png" alt="截屏2024-07-29 10.02.59" style="zoom:25%;" />

<ul>
<li>R-GCN存在问题？参数过多：</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2010.05.34.png" alt="截屏2024-07-29 10.05.34" style="zoom:25%;" />

<ul>
<li><p>每一层的每一种relation类型都对应一个权重$\mathbf{W}_r^{(l)}$，如果关系类型过多，<strong>模型参数量会非常大，容易导致过拟合。</strong></p>
</li>
<li><p>为了防止过拟合，常用的两种正则化方法是<strong>使用块对角矩阵Block Diagonal Matrices</strong>和<strong>基&#x2F;字典学习</strong>：</p>
<ol>
<li><p><strong>使用块对角矩阵：</strong>这种方法通过强制权重矩阵 $\mathbf{W}_r^{(l)}$ 具有块对角结构，从而减少参数数量。具体来说，块对角矩阵<strong>将权重矩阵分成若干个较小的子矩阵（块</strong>），并使得这些子矩阵之间没有相互影响。</p>
<p> 关键思想：<strong>稀疏化权重矩阵</strong></p>
 <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2010.18.21.png" alt="截屏2024-07-29 10.18.21" style="zoom:25%;" />
</li>
<li><p><strong>基&#x2F;字典学习（Basis&#x2F;Dictionary Learning）</strong>:每种关系类型的权重矩阵$\mathbf{W}_r^{(l)}$<strong>由若干基权重矩阵的线性组合表示</strong>。具体来说，定义一组基权重矩阵${ \mathbf{B}_1, \mathbf{B}_2, \ldots, \mathbf{B}_K }$，然后通过关系特定的系数组合这些基权重矩阵来构造每个关系类型的权重矩阵。</p>
<p> 关键思想：使不同的权重矩阵<strong>共享参数</strong></p>
</li>
</ol>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2010.20.11.png" alt="截屏2024-07-29 10.20.11" style="zoom:25%;" /></li>
</ul>
<h4 id="GNN-vs-Heterogenous-GNN"><a href="#GNN-vs-Heterogenous-GNN" class="headerlink" title="GNN vs Heterogenous GNN"></a>GNN vs Heterogenous GNN</h4><ul>
<li><p>两者的区别？</p>
<ol>
<li><p><strong>Message：</strong>消息传递阶段，H-GNN对关系类型建模，不同的关系类型具有不同的linear权重</p>
 <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240729111639298.png" alt="image-20240729111639298" style="zoom:25%;" />

 <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.16.31.png" alt="截屏2024-07-29 11.16.31" style="zoom: 25%;" />
</li>
<li><p><strong>Aggregation：</strong>聚合阶段，H-GNN同样对关系类型进行建模，使用<strong>两阶段的聚合方法</strong>：先对同种关系类型的消息进行聚合，然后进行总的聚合（例如concat）</p>
 <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.18.03.png" alt="截屏2024-07-29 11.18.03" style="zoom:25%;" />

 <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.18.22.png" alt="截屏2024-07-29 11.18.22" style="zoom:25%;" />
</li>
<li><p><strong>Prediction：</strong>在预测阶段，需要考虑不同的关系类型</p>
 <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240729111944075.png" alt="image-20240729111944075" style="zoom:25%;" /></li>
</ol>
</li>
</ul>
<h2 id="Day5"><a href="#Day5" class="headerlink" title="Day5"></a>Day5</h2><h4 id="Knowledge-Graphs"><a href="#Knowledge-Graphs" class="headerlink" title="Knowledge Graphs"></a>Knowledge Graphs</h4><p><img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2011.22.37.png" alt="截屏2024-07-29 11.22.37"></p>
<h4 id="关系模式"><a href="#关系模式" class="headerlink" title="关系模式"></a>关系模式</h4><ol>
<li><p><strong>对称关系（Symmetric Relations）</strong></p>
<p> <strong>定义</strong>：如果关系 ( r(h, t) ) 成立，那么 ( r(t, h) ) 也成立。</p>
<p> <strong>符号表示</strong>：$$ r(h, t) \Rightarrow r(t, h) \forall h, t $$</p>
<p> <strong>示例</strong>：</p>
<ul>
<li><strong>家人（Family）</strong>：如果Alice是Bob的家人，那么Bob也是Alice的家人。</li>
<li><strong>室友（Roommate）</strong>：如果Alice是Bob的室友，那么Bob也是Alice的室友。</li>
</ul>
</li>
<li><p><strong>反对称关系（Antisymmetric Relations）</strong></p>
<p> <strong>定义</strong>：如果关系 ( r(h, t) ) 成立，那么 ( r(t, h) ) 不成立。</p>
<p> <strong>符号表示</strong>：$$ r(h, t) \Rightarrow \neg r(t, h) \forall h, t $$</p>
<p> <strong>示例</strong>：</p>
<ul>
<li><strong>上位词（Hypernym）</strong>：一个词具有更广泛的意义。例如，“狗（dog）”是“贵宾犬（poodle）”的上位词，但反之不成立。</li>
</ul>
</li>
<li><p><strong>逆关系（Inverse Relations）</strong></p>
<p> <strong>定义</strong>：如果关系 ( r(h, t) ) 成立，那么存在一个逆关系 ( r’(t, h) ) 也成立。</p>
<p> <strong>符号表示</strong>：$$ r(h, t) \Rightarrow r’(t, h) $$</p>
<p> <strong>示例</strong>：</p>
<ul>
<li><strong>导师与学生（Advisor and Advisee）</strong>：如果Dr. Smith是John的导师，那么John是Dr. Smith的学生。</li>
</ul>
</li>
<li><p><strong>传递关系（Composition&#x2F;Transitive Relations）</strong></p>
<p> <strong>定义</strong>：如果 ( r(x, y) ) 和 ( r(y, z) ) 都成立，那么 ( r(x, z) ) 也成立。</p>
<p> <strong>符号表示</strong>：$$ r(x, y) \land r(y, z) \Rightarrow r(x, z) \forall x, y, z $$</p>
<p> <strong>示例</strong>：</p>
<ul>
<li><strong>家庭关系</strong>：我母亲的丈夫是我的父亲。如果Alice是Bob的母亲，Bob是Charlie的丈夫，那么Alice是Charlie的母亲。</li>
</ul>
</li>
<li><p><strong>一对多关系（1-to-N Relations）</strong></p>
<p><strong>定义</strong>：一个实体可以与多个实体通过相同关系相关联。</p>
<p><strong>符号表示</strong>：$$ r(h, t_1) , r(h, t_2), \ldots , r(h, t_n) $$ 都成立。</p>
<p><strong>示例</strong>：</p>
<ul>
<li><strong>学生关系（StudentsOf）</strong>：一个教师有多个学生。例如，教师Dr. Smith有学生John、Emily、Sarah。</li>
</ul>
</li>
</ol>
<h4 id="KG-Completion"><a href="#KG-Completion" class="headerlink" title="KG Completion"></a>KG Completion</h4><ul>
<li><p>KG的补全：例如Is link (h,r,t) in the KG?</p>
</li>
<li><p>Introduce <strong>TransE &#x2F; TransR &#x2F; DistMult &#x2F; ComplEx models</strong>【四种<strong>知识图谱嵌入</strong>的方法】 with different embedding space and expressiveness</p>
</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/image-20240729122411091.png" alt="image-20240729122411091" style="zoom: 25%;" />



<h4 id="KG-Reasoning"><a href="#KG-Reasoning" class="headerlink" title="KG Reasoning"></a>KG Reasoning</h4><ul>
<li><strong>知识图谱具体的推理任务需要根据一系列的query来表述</strong>，也就是说在给定的<strong>不完整并且大规模的知识图谱</strong>中对输入的自然语言形式的query进行推理并返回结果，而query可以分为<strong>One-hop Queries，Path Queries和Conjunctive Queries</strong>三种，分别是<strong>单次跳转的推理、多次跳转的推理、联合推理</strong>，可以用下面的图来表示三种query之间的关系：</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.05.59.png" alt="截屏2024-07-29 13.05.59" style="zoom: 33%;" />

<ul>
<li><p><strong>可以使用知识图谱嵌入</strong>：考虑将知识图谱上的问答转化到<strong>向量空间</strong>中进行，而具体的方法就是将query也转换成一个向量，并使用嵌入模型的打分函数来评估结果。一个查询在向量空间中可以表示为：</p>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.10.50.png" alt="截屏2024-07-29 13.10.50" style="zoom: 33%;" /></li>
</ul>
<h4 id="Query2Box"><a href="#Query2Box" class="headerlink" title="Query2Box"></a>Query2Box</h4><blockquote>
<p>论文🔗：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2002.05969">QUERY2BOX: REASONING OVER KNOWLEDGE GRAPHS IN VECTOR SPACE USING BOX EMBEDDINGS</a></p>
</blockquote>
<ul>
<li>问题：在处理<strong>联合推理</strong>时每个节点都代表多个entity，如何<strong>在隐空间定义其交叉操作？</strong></li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.18.02.png" alt="截屏2024-07-29 13.18.02" style="zoom:25%;" />

<ul>
<li><strong>核心思想：</strong>Embed queries with hyper-rectangles (boxes)【<strong>将查询嵌入为超矩形即box</strong>】</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.22.48.png" alt="截屏2024-07-29 13.22.48" style="zoom:33%;" />

<ul>
<li>如何定义多个Box的<strong>交集【intersection】操作</strong>？</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.28.52.png" alt="截屏2024-07-29 13.28.52" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.28.08.png" alt="截屏2024-07-29 13.28.08" style="zoom:25%;" />

<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.30.35.png" alt="截屏2024-07-29 13.30.35" style="zoom:25%;" />



<ul>
<li><strong>对于Union操作的扩展</strong></li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.40.29.png" alt="截屏2024-07-29 13.40.29" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.43.28.png" alt="截屏2024-07-29 13.43.28" style="zoom:25%;" />

<ul>
<li><p><strong>Query2Box的训练</strong></p>
<ol>
<li>在Query2Box模型中，需要<strong>训练的参数主要有所有的实体的嵌入向量，所有的关系的嵌入向量和Intersection运算中的各种参数。</strong></li>
<li>一个很直观的想法是，在训练Qeury2Box模型的过程中，对于一个查询q的嵌入向量，我们要让属于q中的实体v对应的打分函数最大化，而要让不在其中的打分函数最小化，为此需要用到负采样，也就是在训练的过程中，对于每个正样本v随机选取一个负样本与之对应，<strong>具体的训练过程可以分为以下几个步骤：</strong></li>
</ol>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.52.13.png" alt="截屏2024-07-29 13.52.13" style="zoom: 50%;" />

<ol start="3">
<li>在训练之前我们需要提取出一系列查询，而这个过程称为<strong>Query Generation</strong>，可以通过一系列模板生成：</li>
</ol>
  <img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.53.39.png" alt="截屏2024-07-29 13.53.39" style="zoom:25%;" /></li>
</ul>
<h2 id="Day6"><a href="#Day6" class="headerlink" title="Day6"></a>Day6</h2><p><img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.58.25.png" alt="截屏2024-07-29 13.58.25"></p>
<h2 id="Day7"><a href="#Day7" class="headerlink" title="Day7"></a>Day7</h2><p><img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.58.45.png" alt="截屏2024-07-29 13.58.45"></p>
<h2 id="Day8"><a href="#Day8" class="headerlink" title="Day8"></a>Day8</h2><p><img src="https://cdn.jsdelivr.net/gh/02lb/img_picGo@main/img_data/%E6%88%AA%E5%B1%8F2024-07-29%2013.58.53.png" alt="截屏2024-07-29 13.58.53"></p>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Writing</a></li>
        
          <li><a target="_blank" rel="noopener" href="https://github.com/02lb">Projects</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%9B%BE%E8%A1%A8%E7%A4%BA%E5%AD%A6%E4%B9%A0-%E5%9B%BE%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">图表示学习&#x2F;图机器学习</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#GuideLines"><span class="toc-number">1.0.0.1.</span> <span class="toc-text">GuideLines</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day1"><span class="toc-number">1.1.</span> <span class="toc-text">Day1:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Node-Embedding"><span class="toc-number">1.1.1.</span> <span class="toc-text">Node Embedding</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Encoder-Decoder-Framework"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">Encoder - Decoder Framework</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%B8%B8%E8%B5%B0%EF%BC%9ARandom-Walk%EF%BC%9A"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">随机游走：Random Walk：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%80%9D%E6%83%B3%EF%BC%88Idea%EF%BC%89"><span class="toc-number">1.1.1.2.1.</span> <span class="toc-text">思想（Idea）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%EF%BC%88Expressivity%EF%BC%89"><span class="toc-number">1.1.1.2.2.</span> <span class="toc-text">表达能力（Expressivity）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%B4%9F%E9%87%87%E6%A0%B7-Negative-Sampling%EF%BC%9A"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">负采样 Negative Sampling：</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B4%9F%E9%87%87%E6%A0%B7%E7%9A%84%E5%8E%9F%E7%90%86"><span class="toc-number">1.1.1.3.1.</span> <span class="toc-text">负采样的原理</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B4%9F%E6%A0%B7%E6%9C%AC%E6%95%B0%E9%87%8F-K-%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.1.1.3.2.</span> <span class="toc-text">负样本数量 (K) 的选择</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.1.1.3.3.</span> <span class="toc-text">负样本的选择</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%A7%A3%E9%87%8A%E8%B4%9F%E9%87%87%E6%A0%B7%E5%85%AC%E5%BC%8F%E5%8F%8A%E5%85%B6%E5%8E%9F%E7%90%86"><span class="toc-number">1.1.1.3.4.</span> <span class="toc-text">解释负采样公式及其原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Node-Embedding-%EF%BC%9A-DeepWalk-Node2Vec"><span class="toc-number">1.1.2.</span> <span class="toc-text">Node Embedding ： DeepWalk &#x2F; Node2Vec</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Graph-Embedding-%EF%BC%9A%E5%9B%BE%E5%B5%8C%E5%85%A5"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">Graph Embedding ：图嵌入</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day1-Lab"><span class="toc-number">1.2.</span> <span class="toc-text">Day1-Lab:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day2"><span class="toc-number">1.3.</span> <span class="toc-text">Day2:</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#CORE%EF%BC%9AGraph-Neural-Network"><span class="toc-number">1.3.1.</span> <span class="toc-text">CORE：Graph Neural Network</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Graph-vs-Image"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">Graph vs Image</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GNN-Basics"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">GNN Basics</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Classic-GNN"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">Classic GNN</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day3"><span class="toc-number">1.4.</span> <span class="toc-text">Day3</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E5%86%85%E5%AE%B9%EF%BC%9AGNN"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">主要内容：GNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Graph-Manipulation%E3%80%90%E5%9B%BE%E5%A4%84%E7%90%86%E3%80%91"><span class="toc-number">1.4.0.2.</span> <span class="toc-text">Graph Manipulation【图处理】</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#unsupervised-self-supervised"><span class="toc-number">1.4.0.3.</span> <span class="toc-text">unsupervised &#x2F; self- supervised</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87"><span class="toc-number">1.4.0.4.</span> <span class="toc-text">评估指标</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%BE%E6%95%B0%E6%8D%AE%E7%9A%84%E5%88%92%E5%88%86"><span class="toc-number">1.4.0.5.</span> <span class="toc-text">图数据的划分</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#The-Power-of-GNN"><span class="toc-number">1.4.0.6.</span> <span class="toc-text">The Power of GNN</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day3-Lab"><span class="toc-number">1.5.</span> <span class="toc-text">Day3-Lab</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84GCN%E7%94%A8%E4%BA%8E%E8%8A%82%E7%82%B9%E9%A2%84%E6%B5%8B"><span class="toc-number">1.5.0.1.</span> <span class="toc-text">实现一个简单的GCN用于节点预测</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day4"><span class="toc-number">1.6.</span> <span class="toc-text">Day4</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Heterogenous-graphs-%E5%BC%82%E8%B4%A8%E5%9B%BE"><span class="toc-number">1.6.0.1.</span> <span class="toc-text">Heterogenous graphs[异质图]</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E7%B3%BB%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%EF%BC%88Relational-Graph-Convolutional-Network-R-GCN%EF%BC%89"><span class="toc-number">1.6.0.2.</span> <span class="toc-text">关系图卷积网络（Relational Graph Convolutional Network, R-GCN）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GNN-vs-Heterogenous-GNN"><span class="toc-number">1.6.0.3.</span> <span class="toc-text">GNN vs Heterogenous GNN</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day5"><span class="toc-number">1.7.</span> <span class="toc-text">Day5</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Knowledge-Graphs"><span class="toc-number">1.7.0.1.</span> <span class="toc-text">Knowledge Graphs</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E7%B3%BB%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.7.0.2.</span> <span class="toc-text">关系模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KG-Completion"><span class="toc-number">1.7.0.3.</span> <span class="toc-text">KG Completion</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KG-Reasoning"><span class="toc-number">1.7.0.4.</span> <span class="toc-text">KG Reasoning</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Query2Box"><span class="toc-number">1.7.0.5.</span> <span class="toc-text">Query2Box</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day6"><span class="toc-number">1.8.</span> <span class="toc-text">Day6</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day7"><span class="toc-number">1.9.</span> <span class="toc-text">Day7</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Day8"><span class="toc-number">1.10.</span> <span class="toc-text">Day8</span></a></li></ol></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://02lb.github.io/2024/07/21/GraphML-CS224w/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&text=GraphML-CS224w【图机器学习】"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&is_video=false&description=GraphML-CS224w【图机器学习】"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=GraphML-CS224w【图机器学习】&body=Check out this article: https://02lb.github.io/2024/07/21/GraphML-CS224w/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&title=GraphML-CS224w【图机器学习】"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://02lb.github.io/2024/07/21/GraphML-CS224w/&name=GraphML-CS224w【图机器学习】&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://02lb.github.io/2024/07/21/GraphML-CS224w/&t=GraphML-CS224w【图机器学习】"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2024
    Lee
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Writing</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="https://github.com/02lb">Projects</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
